import os
from fastapi import FastAPI, HTTPException, Depends, Query
from pydantic import BaseModel
from vector import retriever
from dotenv import load_dotenv, find_dotenv
import google.generativeai as genai
from sqlalchemy.orm import Session
from sqlalchemy import desc
from database import init_db, get_db, Conversation
from datetime import datetime
from typing import List, Optional

# --- Models for API request and response ---
class AskRequest(BaseModel):
    """Request model expecting a 'question' field."""
    question: str

class AskResponse(BaseModel):
    """Response model returning an 'answer' field."""
    answer: str

class ConversationResponse(BaseModel):
    """Response model for a single conversation."""
    id: int
    question: str
    answer: str
    created_at: datetime

    class Config:
        from_attributes = True

class ConversationsListResponse(BaseModel):
    """Response model for a list of conversations."""
    total: int
    conversations: List[ConversationResponse]

# --- Initialize FastAPI app ---
app = FastAPI(
    title="Nithub QA API",
    description="API to answer questions about Nithub using a curated Q&A knowledge base.",
)

# Initialize database on startup
@app.on_event("startup")
async def startup_event():
    try:
        init_db()
        print("Database initialized successfully")
    except Exception as e:
        print(f"Database initialization error: {e}")

# --- Configure Google Gemini ---
# Load .env from project root if present
_dotenv_path = find_dotenv(usecwd=True)
if _dotenv_path:
    load_dotenv(_dotenv_path)
else:
    load_dotenv()

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise RuntimeError("GOOGLE_API_KEY is not set. Please add it to .env or export it before starting the server.")
print(f"GOOGLE_API_KEY detected: {'*' * (len(api_key) - 4) + api_key[-4:]}\n")
genai.configure(api_key=api_key)
model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash")
gemini_model = genai.GenerativeModel(model_name)

# --- API Endpoint ---
@app.post("/ask", response_model=AskResponse)
async def ask_question(request: AskRequest, db: Session = Depends(get_db)):
    """
    Accepts a question, retrieves relevant reviews,
    and returns an answer generated by the LLM.
    Saves the question and answer to the database.
    """
    question_text = request.question
    print(f"Received question: {question_text}") # Optional: Log received question

    # 1. Retrieve relevant entries
    reviews = retriever.invoke(question_text)
    print(f"Retrieved reviews: {reviews}")

    # Convert retrieved Documents to a compact text context
    if isinstance(reviews, list):
        context_parts = []
        for doc in reviews:
            try:
                context_parts.append(str(getattr(doc, "page_content", doc)))
            except Exception:
                context_parts.append(str(doc))
        context_block = "\n\n".join(context_parts)
    else:
        context_block = str(reviews)

    # 2. Build the prompt and call Gemini
    prompt_text = (
        "You are an expert assistant answering questions about Nithub (an innovation hub in Lagos).\n\n"
        "INSTRUCTIONS:\n"
        "- Use the knowledge entries provided below to answer the question.\n"
        "- You can combine information from multiple entries to provide a complete answer.\n"
        "- When referring to Nithub, always use 'we' or 'our' (first person from Nithub's perspective), never 'they' or 'their'.\n"
        "- If the question asks about location/where, use any location information from the entries.\n"
        "- If the question asks 'why', provide relevant context from the entries that explains the reason.\n"
        "- Answer in a natural, helpful way based on the provided knowledge entries.\n"
        "- If the question cannot be answered from the provided entries at all, then respond with: 'I don't have that information in my knowledge base. Please contact Nithub directly for this information.'\n\n"
        f"Knowledge entries from CSV:\n{context_block}\n\n"
        f"Question: {question_text}\n\n"
        "Answer based on the knowledge entries above, using 'we' or 'our' when referring to Nithub:"
    )

    try:
        gemini_response = gemini_model.generate_content(prompt_text)
    except Exception as e:
        raise HTTPException(status_code=502, detail=f"Gemini API error using model '{model_name}': {e}")
    result_text = getattr(gemini_response, "text", "") or str(gemini_response)

    # 3. Normalize whitespace to avoid \n in responses
    cleaned_answer = " ".join(result_text.split())

    # 4. Save to database
    try:
        conversation = Conversation(
            question=question_text,
            answer=cleaned_answer,
            created_at=datetime.utcnow()
        )
        db.add(conversation)
        db.commit()
        db.refresh(conversation)
        print(f"Saved conversation ID: {conversation.id}")
    except Exception as e:
        print(f"Database save error: {e}")
        db.rollback()
        # Continue execution even if DB save fails

    # 5. Return the cleaned result
    return AskResponse(answer=cleaned_answer)

# --- Get conversations endpoint ---
@app.get("/conversations", response_model=ConversationsListResponse)
async def get_conversations(
    limit: int = Query(default=50, ge=1, le=100, description="Maximum number of conversations to return"),
    offset: int = Query(default=0, ge=0, description="Number of conversations to skip"),
    db: Session = Depends(get_db)
):
    """
    Retrieve stored conversations (questions and answers) from the database.
    
    - **limit**: Maximum number of conversations to return (1-100, default: 50)
    - **offset**: Number of conversations to skip for pagination (default: 0)
    
    Returns conversations ordered by most recent first.
    """
    try:
        # Get total count
        total = db.query(Conversation).count()
        
        # Get paginated conversations, ordered by most recent first
        conversations = db.query(Conversation)\
            .order_by(desc(Conversation.created_at))\
            .offset(offset)\
            .limit(limit)\
            .all()
        
        return ConversationsListResponse(
            total=total,
            conversations=[ConversationResponse.model_validate(conv) for conv in conversations]
        )
    except Exception as e:
        print(f"Error retrieving conversations: {e}")
        raise HTTPException(status_code=500, detail=f"Error retrieving conversations: {str(e)}")

# --- Get single conversation by ID ---
@app.get("/conversations/{conversation_id}", response_model=ConversationResponse)
async def get_conversation(conversation_id: int, db: Session = Depends(get_db)):
    """
    Retrieve a single conversation by its ID.
    """
    conversation = db.query(Conversation).filter(Conversation.id == conversation_id).first()
    if not conversation:
        raise HTTPException(status_code=404, detail="Conversation not found")
    return ConversationResponse.model_validate(conversation)

# --- (Optional) Add a root endpoint for basic check ---
@app.get("/")
async def root():
    return {"message": "Nithub QA API is running!"}
